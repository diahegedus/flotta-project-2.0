import streamlit as st
import pandas as pd
import google.generativeai as genai
import json
import os
import io
import time
from datetime import datetime

# --- 1. HITEL√âS√çT√âSI RENDSZER ---
def check_password():
    def password_entered():
        user = st.session_state["username"]
        pwd = st.session_state["password"]
        
        if "users" in st.secrets and user in st.secrets["users"]:
            if st.secrets["users"][user]["password"] == pwd:
                st.session_state["password_correct"] = True
                st.session_state["logged_in_user"] = user
                st.session_state["role"] = st.secrets["users"][user]["role"]
                del st.session_state["password"]
                del st.session_state["username"]
                return
        
        st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        st.title("üîí Bejelentkez√©s")
        st.text_input("Felhaszn√°l√≥n√©v", on_change=password_entered, key="username")
        st.text_input("Jelsz√≥", type="password", on_change=password_entered, key="password")
        return False
    elif not st.session_state["password_correct"]:
        st.title("üîí Bejelentkez√©s")
        st.text_input("Felhaszn√°l√≥n√©v", on_change=password_entered, key="username")
        st.text_input("Jelsz√≥", type="password", on_change=password_entered, key="password")
        st.error("Hib√°s felhaszn√°l√≥n√©v vagy jelsz√≥.")
        return False
    else:
        return True

if check_password():
    # --- KONFIGUR√ÅCI√ì ---
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
        genai.configure(api_key=api_key)
    except KeyError:
        st.error("Kritikus hiba: API kulcs nem tal√°lhat√≥.")
        st.stop()

    DB_FILE = "masterdata_forgalmi.csv"
    
    # √öj oszlopok a mez≈ënk√©nti confidence score-okhoz
    EXPECTED_FIELDS = [
        "Dokumentum_Tipus", "Alvazszam", "Rendszam", "Vevo_Tulajdonos", 
        "Elado", "Brutto_Vetelar", "Teljesitmeny_kW", "Hengerurtartalom_cm3", "Elso_forgalomba_helyezes"
    ]
    CONF_FIELDS = [f"{f}_Conf" for f in EXPECTED_FIELDS]

    # --- MASTER DATA KEZEL√âS ---
    def load_data():
        if os.path.exists(DB_FILE):
            df = pd.read_csv(DB_FILE)
            if "Feltolto_User" not in df.columns: df["Feltolto_User"] = "ismeretlen"
            if "Hiba_Oka" not in df.columns: df["Hiba_Oka"] = ""
            if "Confidence_Score" not in df.columns: df["Confidence_Score"] = 100
            for conf_f in CONF_FIELDS:
                if conf_f not in df.columns: df[conf_f] = 0
            return df
        
        cols = EXPECTED_FIELDS + CONF_FIELDS + [
            "Feldolgozasi_Statusz", "Utolso_Modositas_Ideje", 
            "Feltolto_User", "Hiba_Oka", "Confidence_Score"
        ]
        return pd.DataFrame(columns=cols)

    def save_data(df):
        df.to_csv(DB_FILE, index=False)

    def upsert_record(new_data_dict):
        df = load_data()
        alvaz = new_data_dict.get("Alvazszam")
        
        new_data_dict["Utolso_Modositas_Ideje"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        new_data_dict["Feltolto_User"] = st.session_state["logged_in_user"]

        if alvaz and str(alvaz).lower() not in ["null", "none", ""]:
            if alvaz in df["Alvazszam"].values:
                idx = df.index[df['Alvazszam'] == alvaz][0]
                for key, value in new_data_dict.items():
                    if value is not None and str(value).lower() not in ["null", "none", ""]: 
                        df.at[idx, key] = value
                save_data(df)
                return "update"
            else:
                new_row = pd.DataFrame([new_data_dict])
                df = pd.concat([df, new_row], ignore_index=True)
                save_data(df)
                return "new"
        
        new_data_dict["Alvazszam"] = f"ISMERETLEN_{int(time.time())}"
        new_row = pd.DataFrame([new_data_dict])
        df = pd.concat([df, new_row], ignore_index=True)
        save_data(df)
        return "new"

    # --- 2. VALID√ÅCI√ìS R√âTEG (HIBRID: AI Score + Szab√°lyok) ---
    def validate_ocr_output(data):
        errors = []
        
        if not data:
            return False, "Nem valid JSON / AI hiba", 0

        # √Åtlagos AI confidence sz√°m√≠t√°sa a mez≈ëkb≈ël
        total_conf = 0
        valid_fields = 0
        for f in EXPECTED_FIELDS:
            conf_val = data.get(f"{f}_Conf", 0)
            if isinstance(conf_val, (int, float)):
                total_conf += conf_val
                valid_fields += 1
        
        avg_score = (total_conf / valid_fields) if valid_fields > 0 else 0

        doc_type = data.get("Dokumentum_Tipus")
        if not doc_type or str(doc_type).lower() == "null":
            errors.append("Hi√°nyz√≥ Dokumentum T√≠pus")
            avg_score -= 20

        alvaz = data.get("Alvazszam")
        if not alvaz or str(alvaz).lower() == "null":
            errors.append("Hi√°nyz√≥ Alv√°zsz√°m")
            avg_score -= 40
            data["Alvazszam_Conf"] = 0 # Biztosan rossz
        else:
            clean_alvaz = str(alvaz).replace(" ", "").replace("-", "")
            if len(clean_alvaz) != 17:
                errors.append(f"√ârv√©nytelen VIN hossz ({len(clean_alvaz)} kar.)")
                avg_score -= 40
                data["Alvazszam_Conf"] = 0 # Szab√°ly fel√ºl√≠rja az AI magabiztoss√°g√°t

        if str(doc_type).lower() == "sz√°mla":
            vetelar = data.get("Brutto_Vetelar")
            if not vetelar or str(vetelar).lower() in ["null", "none", ""]:
                errors.append("Hi√°nyz√≥ V√©tel√°r (Sz√°mla)")
                avg_score -= 20

        # Ha b√°rmelyik mez≈ë magabiztoss√°ga 80% alatti, k√ºldj√ºk ellen≈ërz√©sre!
        low_conf_fields = [f for f in EXPECTED_FIELDS if data.get(f"{f}_Conf", 0) < 80 and str(data.get(f, "")).lower() not in ["null", "none", ""]]
        if low_conf_fields:
            errors.append(f"Alacsony AI magabiztoss√°g: {', '.join(low_conf_fields)}")

        final_score = max(0, min(100, avg_score)) # 0-100 k√∂z√∂tt tartjuk

        if errors:
            return False, " | ".join(errors), final_score
        return True, "", final_score

    # --- AI KINYER√âS √âS JSON LAP√çT√ÅS ---
    def process_document_with_gemini(uploaded_file):
        try:
            available_models = [m.name.replace('models/', '') for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        except:
            available_models = []
            
        preferred_order = ['gemini-1.5-flash', 'gemini-1.5-pro']
        models_to_try = [m for m in preferred_order if m in available_models] or (available_models[:1] if available_models else [])

        # V√ÅLTOZ√ÅS: Nested JSON form√°tumot k√©r√ºnk value √©s confidence p√°rosokkal!
        prompt = """
        Elemezd a dokumentumot (forgalmi vagy sz√°mla) √©s add vissza az adatokat szigor√∫an az al√°bbi JSON strukt√∫r√°ban!
        Minden mez≈ëh√∂z k√∂telez≈ëen meg kell adnod egy "value" (√©rt√©k) √©s egy "confidence" (0-100 k√∂z√∂tti magabiztoss√°gi sz√°zal√©k) p√°rost.
        
        P√©lda form√°tum:
        {
          "Dokumentum_Tipus": {"value": "Sz√°mla", "confidence": 100},
          "Alvazszam": {"value": "WBA1234567890ABCD", "confidence": 95}
        }
        
        Kinyerend≈ë mez≈ëk:
        - Dokumentum_Tipus ("Forgalmi" vagy "Sz√°mla")
        - Alvazszam (17 karakteres VIN)
        - Rendszam 
        - Vevo_Tulajdonos (Vev≈ë vagy C.1 k√≥d)
        - Elado (Csak sz√°mla eset√©n)
        - Brutto_Vetelar (Csak sz√°mla eset√©n, sz√°m√©rt√©k)
        - Teljesitmeny_kW (P.2 k√≥d)
        - Hengerurtartalom_cm3 (P.1 k√≥d)
        - Elso_forgalomba_helyezes (B k√≥d)

        Csak a nyers JSON-t add vissza!
        """
        pdf_part = {"mime_type": "application/pdf", "data": uploaded_file.getvalue()}
        
        for model_name in models_to_try:
            try:
                model = genai.GenerativeModel(model_name)
                response = model.generate_content([prompt, pdf_part])
                clean_text = response.text.replace('```json', '').replace('```', '').strip()
                raw_json = json.loads(clean_text)
                
                # JSON LAP√çT√ÅSA (Flattening) az adatb√°zishoz
                flat_data = {}
                for field in EXPECTED_FIELDS:
                    if field in raw_json and isinstance(raw_json[field], dict):
                        flat_data[field] = raw_json[field].get("value")
                        # Ha az AI null-t ad vissza, a confidence legyen 0
                        if str(flat_data[field]).lower() in ["null", "none", ""]:
                            flat_data[f"{field}_Conf"] = 0
                        else:
                            flat_data[f"{field}_Conf"] = raw_json[field].get("confidence", 0)
                    else:
                        flat_data[field] = raw_json.get(field)
                        flat_data[f"{field}_Conf"] = 0
                
                return flat_data
            except Exception as e:
                continue
        return None

    # --- OLDALS√ÅV ---
    with st.sidebar:
        current_user = st.session_state['logged_in_user']
        current_role = st.session_state['role']
        st.write(f"üë§ Felhaszn√°l√≥: **{current_user}**")
        st.write(f"üõ°Ô∏è Szerepk√∂r: *{current_role.capitalize()}*")
        
        if st.sidebar.button("Kijelentkez√©s"):
            for key in ["password_correct", "logged_in_user", "role"]:
                if key in st.session_state:
                    del st.session_state[key]
            st.rerun()

    # =========================================================
    # K√ñZ√ñS FELDOLGOZ√ì LOGIKA
    # =========================================================
    def run_processing_pipeline(uploaded_files):
        progress_bar = st.progress(0)
        status_placeholder = st.empty()
        new_recs, updated_recs, validation_fails, critical_errors = 0, 0, 0, 0

        for i, file in enumerate(uploaded_files):
            status_placeholder.text(f"St√°tusz: AI Kinyer√©s √©s Pontoz√°s - {file.name}")
            extracted_data = process_document_with_gemini(file)
            
            if extracted_data:
                is_valid, error_reason, conf_score = validate_ocr_output(extracted_data)
                
                extracted_data["Confidence_Score"] = conf_score
                
                if is_valid:
                    extracted_data["Feldolgozasi_Statusz"] = "K√©sz"
                    extracted_data["Hiba_Oka"] = ""
                else:
                    extracted_data["Feldolgozasi_Statusz"] = "Valid√°ci√≥_Sz√ºks√©ges"
                    extracted_data["Hiba_Oka"] = error_reason
                    validation_fails += 1
                
                status = upsert_record(extracted_data)
                if status == "new": new_recs += 1
                elif status == "update": updated_recs += 1
            else:
                critical_errors += 1
                error_data = {
                    "Dokumentum_Tipus": "Ismeretlen",
                    "Feldolgozasi_Statusz": "Hiba",
                    "Hiba_Oka": "Nem valid JSON / AI hiba",
                    "Confidence_Score": 0
                }
                upsert_record(error_data)
            
            progress_bar.progress((i + 1) / len(uploaded_files))
            if i < len(uploaded_files) - 1: time.sleep(4)

        success_msg = f"Feldolgoz√°s befejezve! √öj: {new_recs} | Friss√≠tett: {updated_recs} | Hiba: {critical_errors}"
        if validation_fails > 0 or critical_errors > 0:
            st.warning(f"{success_msg} ‚ö†Ô∏è {validation_fails} dokumentum emberi ellen≈ërz√©st ig√©nyel az alacsony megb√≠zhat√≥s√°g miatt!")
        else:
            st.success(success_msg)


    # =========================================================
    # ADMIN N√âZET
    # =========================================================
    if st.session_state["role"] == "admin":
        st.title("üöó Flotta Admin Vez√©rl≈ëpult")
        
        df_admin = load_data()
        
        # --- HIBAKEZEL√âSI DASHBOARD ---
        st.subheader("üö® AI Megb√≠zhat√≥s√°gi Dashboard (Field-Level Confidence)")
        if not df_admin.empty:
            df_errors = df_admin[df_admin["Feldolgozasi_Statusz"].isin(["Valid√°ci√≥_Sz√ºks√©ges", "Hiba"])]
            
            col1, col2, col3, col4 = st.columns(4)
            avg_score = df_admin["Confidence_Score"].mean() if "Confidence_Score" in df_admin.columns else 0
            
            col1.metric("Manu√°lis Ellen≈ërz√©s Kell", len(df_errors))
            col2.metric("√Åtlagos Rendszer Score", f"{avg_score:.1f}%")
            col3.metric("√ñsszes Dokumentum", len(df_admin))
            col4.metric("AI Hib√°k", len(df_admin[df_admin["Feldolgozasi_Statusz"] == "Hiba"]))

            st.markdown("<br>", unsafe_allow_html=True)
            
            tab1, tab2, tab3 = st.tabs(["üìå Mez≈ës Szint≈± Analitika (Alacsony Pontsz√°mok)", "üìå Hib√°s/Hi√°nyz√≥ Adatok", "üìå Nyers JSON √ñsszeoml√°sok"])
            
            with tab1:
                st.markdown("Az AI az al√°bbi dokumentumokn√°l **bizonyos mez≈ëkben bizonytalan** (<80%), ez√©rt ellen≈ërz√©sre k√ºldte ≈ëket.")
                if not df_errors.empty:
                    # Kigy≈±jtj√ºk a legfontosabb mez≈ëket √©s azok pontsz√°mait megjelen√≠t√©sre
                    disp_cols = ["Alvazszam", "Alvazszam_Conf", "Rendszam", "Rendszam_Conf", "Brutto_Vetelar", "Brutto_Vetelar_Conf", "Hiba_Oka"]
                    # Csak azokat az oszlopokat mutatjuk, amik t√©nyleg l√©teznek a df-ben
                    disp_cols = [c for c in disp_cols if c in df_errors.columns]
                    st.dataframe(df_errors[disp_cols].sort_values(by="Alvazszam_Conf", ascending=True), use_container_width=True, hide_index=True)
            
            with tab2:
                df_missing = df_errors[df_errors["Hiba_Oka"].str.contains("Hi√°nyz√≥|√ârv√©nytelen", na=False, case=False)]
                if not df_missing.empty:
                    st.dataframe(df_missing[["Alvazszam", "Dokumentum_Tipus", "Hiba_Oka", "Confidence_Score"]], use_container_width=True, hide_index=True)
            
            with tab3:
                df_json = df_errors[df_errors["Feldolgozasi_Statusz"] == "Hiba"]
                if not df_json.empty:
                    st.dataframe(df_json[["Alvazszam", "Feldolgozasi_Statusz", "Hiba_Oka"]], use_container_width=True, hide_index=True)

        st.divider()
        st.subheader("1. K√©zi dokumentum feldolgoz√°s")
        uploaded_files = st.file_uploader("V√°lassza ki a PDF f√°jlokat", type=['pdf'], accept_multiple_files=True)

        if uploaded_files:
            if st.button(f"{len(uploaded_files)} f√°jl feldolgoz√°s√°nak ind√≠t√°sa"):
                run_processing_pipeline(uploaded_files)

        st.divider()
        with st.expander("üóÑÔ∏è Teljes Master Data (AI Magabiztoss√°gi Pontokkal)"):
            if not df_admin.empty:
                st.dataframe(df_admin, use_container_width=True, hide_index=True)
                db_output = io.BytesIO()
                with pd.ExcelWriter(db_output, engine='openpyxl') as writer:
                    df_admin.to_excel(writer, index=False, sheet_name='Master_Data')
                st.download_button("Export√°l√°s Excelbe", data=db_output.getvalue(), file_name='master_data_teljes.xlsx')

    # =========================================================
    # √úGYF√âL N√âZET
    # =========================================================
    elif st.session_state["role"] == "ugyfel":
        st.title("üìÅ Dokumentum Felt√∂lt≈ë K√∂zpont")
        
        uploaded_files = st.file_uploader("PDF f√°jlok kiv√°laszt√°sa", type=['pdf'], accept_multiple_files=True)
        if uploaded_files:
            if st.button(f"{len(uploaded_files)} f√°jl bek√ºld√©se feldolgoz√°sra", type="primary"):
                run_processing_pipeline(uploaded_files)

        st.divider()
        st.subheader("Beker√ºlt dokumentumaim √°llapota")
        df_all = load_data()
        if not df_all.empty:
            df_client = df_all[df_all["Feltolto_User"] == current_user]
            if not df_client.empty:
                display_cols = ["Alvazszam", "Dokumentum_Tipus", "Feldolgozasi_Statusz"]
                st.dataframe(df_client[display_cols], use_container_width=True, hide_index=True)
            else:
                st.info("M√©g nem t√∂lt√∂tt fel dokumentumot.")
